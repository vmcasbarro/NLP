from nltk.tokenize import sent_tokenize, word_tokenize

data = "All work and no play makes jack a dull boy, all work and no play"
print(word_tokenize(data))

# output:
['All', 'work', 'and', 'no', 'play', 'makes', 'jack', 'dull', 'boy', ',', 'all', 'work', 'and', 'no', 'play']



from nltk.tokenize import sent_tokenize, word_tokenize

data = "All work and no play makes jack dull boy. All work and no play makes jack a dull boy."
print(sent_tokenize(data))

# output:
['All work and no play makes jack dull boy.', 'All work and no play makes jack a dull boy.']



democracy,Â democratic, &Â democratization => ?



â˜¹ï¸  ğŸ˜  ğŸ¤—
-1  0  1



"John","likes","to","watch","movies","Mary","likes","movies","too"
BoW1 = {"John":1,"likes":2,"to":1,"watch":1,"movies":2,"Mary":1,"too":1};

"John","also","likes","to","watch","football","games"
BoW2 = {"John":1,"also":1,"likes":1,"to":1,"watch":1,"football":1,"games":1};
